# ğŸ”§ MEC Previsioni

**Sistema di analisi predittiva per la manutenzione di componenti meccanici**

[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/downloads/)
[![Flask Version](https://img.shields.io/badge/flask-3.1.0-green.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/license-Proprietary-red.svg)]()
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

---

## ğŸ“‹ Tabella dei Contenuti

- [Panoramica](#-panoramica)
- [Caratteristiche](#-caratteristiche)
- [Requisiti](#-requisiti)
- [Installazione](#-installazione)
- [Configurazione](#-configurazione)
- [Utilizzo](#-utilizzo)
- [Architettura](#-architettura)
- [Sviluppo](#-sviluppo)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Troubleshooting](#-troubleshooting)
- [Licenza](#-licenza)

---

## ğŸ¯ Panoramica

**MEC Previsioni** Ã¨ un'applicazione web sviluppata in Flask per la **gestione e l'analisi predittiva delle rotture di componenti meccanici**.

Il sistema implementa modelli di **survival analysis** (Kaplan-Meier e distribuzioni Weibull) per prevedere quando i componenti potrebbero guastarsi, permettendo una **pianificazione ottimale degli ordini di acquisto** e una manutenzione preventiva efficace.

### Il Problema

Le aziende che gestiscono macchinari complessi devono:
- Prevedere quando i componenti potrebbero guastarsi
- Ottimizzare gli ordini di ricambi evitando sprechi
- Minimizzare i fermi macchina non pianificati
- Analizzare pattern di rottura storici

### La Soluzione

MEC Previsioni analizza dati storici di rottura e utilizza modelli statistici avanzati per:
- âœ… Stimare la probabilitÃ  di guasto nel tempo
- âœ… Calcolare intervalli di confidenza delle previsioni
- âœ… Suggerire quantitÃ  ottimali per ordini futuri
- âœ… Visualizzare curve di sopravvivenza per componente
- âœ… Tracciare elaborazioni e gestire file dati

---

## âœ¨ Caratteristiche

### Core Features

- ğŸ”¬ **Survival Analysis**
  - Kaplan-Meier (stima non parametrica)
  - Weibull Bayesiano (modello parametrico)
  - Confidence bands con bootstrap

- ğŸ“Š **Gestione Dati (4 Pipeline)**
  - Upload file PDF (ordini di acquisto)
  - Upload file Excel (anagrafiche BOM, rotture)
  - Upload file TSV (stock giacenze)
  - Parsing automatico con validazione
  - Tracciamento stato elaborazioni
  - Storicizzazione modifiche

- ğŸ“ˆ **Visualizzazioni**
  - Curve di sopravvivenza
  - Grafici Weibull fit
  - Dashboard KPI
  - Export grafici PNG/JSON

- ğŸ” **Sicurezza**
  - Autenticazione utenti (Flask-Login)
  - Gestione ruoli (admin/user)
  - Password hashing (Werkzeug)
  - CSRF protection
  - Session management

- ğŸ—„ï¸ **Database**
  - SQLite (development)
  - PostgreSQL (production)
  - Migrazioni versionare (Flask-Migrate)
  - User tracking (created_by, updated_by)

---

## ğŸ“‹ Requisiti

### Sistema

- **Python**: >= 3.9
- **Database**:
  - SQLite 3.x (development)
  - PostgreSQL 12+ (production, opzionale)
- **Sistema Operativo**: Linux, macOS, Windows

### Python Packages

Vedere [`requirements.txt`](requirements.txt) per la lista completa.

**Principali dipendenze:**
- Flask 3.1.0
- pandas 2.2.3
- numpy 2.1.3
- lifelines 0.29.0 (survival analysis)
- matplotlib 3.9.2
- Flask-SQLAlchemy 3.1.1
- gunicorn 23.0.0 (production)

---

## ğŸš€ Installazione

### 1. Clone Repository

```bash
git clone <repository-url>
cd mec-previsioni
```

### 2. Virtual Environment

```bash
# Crea virtual environment
python -m venv venv

# Attiva virtual environment
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate
```

### 3. Installa Dipendenze

#### Opzione A: SQLite (Consigliato per Development/Windows)

**Nessuna dipendenza aggiuntiva richiesta!** SQLite Ã¨ incluso in Python.

```bash
# Production
pip install -r requirements.txt

# Development (include testing e linting)
pip install -r requirements-dev.txt
```

#### Opzione B: PostgreSQL (Production)

**Linux/macOS:**
```bash
# Installa dipendenze base + PostgreSQL driver
pip install -r requirements-postgres.txt
```

**Windows:**

âš ï¸ **NOTA**: Su Windows, psycopg2-binary richiede Visual C++ Build Tools.

**Consigliato**: Usa SQLite (opzione A sopra) per evitare problemi di compilazione.

Se hai bisogno di PostgreSQL:

1. **Installa Visual C++ Build Tools**
   - Scarica da: [Visual Studio Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
   - Seleziona "Desktop development with C++"
   - Installa (puÃ² richiedere 3-7 GB)

2. **Installa dipendenze PostgreSQL**
   ```bash
   pip install -r requirements-postgres.txt
   ```

**Alternativa Windows**: Usa wheel pre-compilato
```bash
# 1. Scarica wheel da: https://www.lfd.uci.edu/~gohlke/pythonlibs/#psycopg
# 2. Installa wheel
pip install psycopg2â€‘2.9.9â€‘cp39â€‘cp39â€‘win_amd64.whl
# 3. Installa resto dipendenze
pip install -r requirements.txt
```

### 4. Configurazione

```bash
# Copia template di configurazione
cp .env.example .env

# Genera SECRET_KEY sicura
python -c 'import secrets; print(secrets.token_urlsafe(32))'

# Modifica .env e aggiungi SECRET_KEY
nano .env
```

### 5. Inizializza Database

```bash
# Il database viene creato automaticamente al primo avvio
python app.py

# Le credenziali di default saranno in logs/app.log
```

---

## âš™ï¸ Configurazione

### Variabili d'Ambiente (.env)

File: `.env` (creato da `.env.example`)

```bash
# Flask Configuration
SECRET_KEY=your-secret-key-here

# Database (opzionale, default: SQLite)
# DATABASE_URL=postgresql://user:password@localhost:5432/mec_previsioni

# Default User Passwords (opzionale)
# ADMIN_DEFAULT_PASSWORD=secure-password
# DEMO_DEFAULT_PASSWORD=secure-password

# File Paths (opzionale, per personalizzare percorsi dati)
# ROTTURE_FILE_PATH=/custom/path/to/rotture.xlsx
# ANAGRAFICA_FILE_PATH=/custom/path/to/anagrafica.xlsx
```

### Configurazione Database

**SQLite (Development):**
```python
# Automatico, nessuna configurazione necessaria
# Database creato in: instance/mec.db
```

**PostgreSQL (Production):**
```bash
# 1. Avvia PostgreSQL con Docker
docker compose -f docker-compose.postgres.yml up -d

# 2. Configura .env
DATABASE_URL=postgresql://mec:password@localhost:5432/mec_previsioni

# 3. Avvia applicazione
python app.py
```

---

## ğŸ“– Utilizzo

### Avvio Applicazione

**Development:**
```bash
python app.py
```

**Production (con Gunicorn):**
```bash
gunicorn -w 4 -b 0.0.0.0:5010 "app:create_app()"
```

### Accesso Web UI

```
URL: http://localhost:5010
```

**Credenziali di default:**
- **Admin**: `admin` / (vedi `logs/app.log` al primo avvio)
- **Demo**: `demo` / (vedi `logs/app.log` al primo avvio)

âš ï¸ **IMPORTANTE**: Cambiare le password dopo il primo login!

### Workflow Tipico

1. **Login** con credenziali admin
2. **Upload File** per le 4 pipeline:
   - **Ordini**: File PDF ordini di acquisto
   - **Anagrafiche**: File Excel con distinte base (BOM) componenti
   - **Rotture**: File Excel con storico rotture
   - **Stock**: File TSV con giacenze magazzino
3. **Elabora Dati**: Processa file caricati (parsing automatico)
4. **Esplora Dati**: Usa Explorer per cercare e filtrare dati elaborati
5. **Visualizza Previsioni**: Accedi a dashboard previsioni e statistiche
6. **Export Risultati**: Scarica CSV, grafici e JSON

---

## ğŸ—ï¸ Architettura

### Struttura Directory

```
mec-previsioni/
â”œâ”€â”€ app.py                      # Entry point Flask
â”œâ”€â”€ config.py                   # Configurazioni (Dev/Prod)
â”œâ”€â”€ models.py                   # Modelli SQLAlchemy
â”œâ”€â”€ forms.py                    # WTForms validazione
â”œâ”€â”€ functions.py                # Analisi statistica
â”œâ”€â”€ preprocessing.py            # Elaborazione dati
â”‚
â”œâ”€â”€ routes/                     # Blueprint Flask
â”‚   â”œâ”€â”€ auth.py                # Autenticazione
â”‚   â”œâ”€â”€ ordini.py              # Pipeline Ordini (PDF)
â”‚   â”œâ”€â”€ ordini_explorer.py     # Ordini Explorer
â”‚   â”œâ”€â”€ anagrafiche.py         # Pipeline Anagrafiche (Excel)
â”‚   â”œâ”€â”€ anagrafiche_catalogo.py # Catalogo Modelli & Componenti
â”‚   â”œâ”€â”€ rotture.py             # Pipeline Rotture (Excel)
â”‚   â”œâ”€â”€ rotture_explorer.py    # Rotture Explorer
â”‚   â”œâ”€â”€ stock.py               # Pipeline Stock (TSV)
â”‚   â”œâ”€â”€ stock_explorer.py      # Stock Explorer
â”‚   â”œâ”€â”€ previsioni.py          # Calcolo previsioni
â”‚   â”œâ”€â”€ users.py               # Gestione utenti
â”‚   â””â”€â”€ dashboard.py           # Dashboard KPI
â”‚
â”œâ”€â”€ templates/                  # Template Jinja2
â”‚   â”œâ”€â”€ base.html              # Layout base
â”‚   â”œâ”€â”€ home.html              # Homepage
â”‚   â”œâ”€â”€ help.html              # Guida utente
â”‚   â”œâ”€â”€ errors/                # Pagine errore
â”‚   â”œâ”€â”€ dashboard/             # Dashboard elaborazioni
â”‚   â”œâ”€â”€ ordini/                # Template ordini
â”‚   â”œâ”€â”€ anagrafiche/           # Template anagrafiche
â”‚   â”œâ”€â”€ rotture/               # Template rotture
â”‚   â”œâ”€â”€ stock/                 # Template stock
â”‚   â””â”€â”€ previsioni/            # Template previsioni
â”‚
â”œâ”€â”€ utils/                      # Utility
â”‚   â”œâ”€â”€ decorators.py          # @admin_required, @handle_errors
â”‚   â””â”€â”€ db_log.py              # Logging database
â”‚
â”œâ”€â”€ static/                     # Asset statici
â”‚   â”œâ”€â”€ images/                # Immagini
â”‚   â”œâ”€â”€ pred_charts/           # Grafici generati
â”‚   â””â”€â”€ pred_charts_stat/      # Grafici statistici
â”‚
â”œâ”€â”€ migrations/                 # Database migrations
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ logs/                       # Log applicazione
â”œâ”€â”€ instance/                   # Database SQLite
â”‚
â”œâ”€â”€ INPUT/                      # File input (git-ignored)
â”‚   â”œâ”€â”€ ordini/                # PDF ordini da elaborare
â”‚   â”œâ”€â”€ anagrafiche/           # Excel BOM da elaborare
â”‚   â”œâ”€â”€ rotture/               # Excel rotture da elaborare
â”‚   â””â”€â”€ stock/                 # TSV giacenze da elaborare
â”‚
â””â”€â”€ OUTPUT/                     # File output (git-ignored)
    â”œâ”€â”€ ordini/                # PDF elaborati
    â”œâ”€â”€ anagrafiche/           # Excel elaborati
    â”œâ”€â”€ rotture/               # Excel elaborati
    â””â”€â”€ stock/                 # TSV elaborati
```

### Stack Tecnologico

| Layer | Tecnologia |
|-------|------------|
| **Backend** | Flask 3.x |
| **Database** | PostgreSQL / SQLite |
| **ORM** | SQLAlchemy |
| **Data Analysis** | Pandas, NumPy |
| **Statistical Models** | Lifelines (Kaplan-Meier, Weibull) |
| **Visualization** | Matplotlib |
| **Authentication** | Flask-Login, Werkzeug |
| **Forms** | WTForms |
| **Server** | Gunicorn |

### Modelli Database (Principali)

- **User**: Autenticazione e autorizzazione
- **FileAnagrafica**: Tracking file anagrafiche Excel
- **FileRottura**: Tracking file rotture storiche
- **FileOrdine**: Tracking ordini di acquisto
- **Modello**: Anagrafica modelli prodotto
- **Componente**: Anagrafica componenti
- **Rottura**: Eventi di guasto
- **TraceElab**: Tracciamento elaborazioni

Vedere [`MODELS_STRUCTURE.md`](MODELS_STRUCTURE.md) per dettagli.

---

## ğŸ› ï¸ Sviluppo

### Setup Ambiente di Sviluppo

```bash
# Installa dipendenze dev
pip install -r requirements-dev.txt

# Installa pre-commit hooks
pre-commit install
```

### Comandi Makefile

```bash
# Mostra tutti i comandi disponibili
make help

# Formatta codice
make format

# Linting
make lint

# Test
make test

# Coverage
make test-cov

# CI completo (format + lint + test)
make ci
```

### Code Quality Tools

- **Black**: Code formatter (88 char line length)
- **isort**: Import sorting
- **flake8**: PEP8 linting
- **pylint**: Advanced static analysis
- **mypy**: Type checking
- **bandit**: Security checks
- **pre-commit**: Automatic hooks

### Workflow di Sviluppo

1. Crea feature branch: `git checkout -b feature/nome-feature`
2. Sviluppa e testa localmente
3. Formatta codice: `make format`
4. Lint: `make lint`
5. Test: `make test`
6. Commit (pre-commit hooks si attivano automaticamente)
7. Push e crea Pull Request

Vedere [`DEVELOPMENT.md`](DEVELOPMENT.md) per guida completa.

---

## âœ… Testing

### Esegui Test

```bash
# Tutti i test
pytest

# Con coverage
pytest --cov --cov-report=html

# Solo unit test
pytest -m unit

# Solo integration test
pytest -m integration

# Test specifico
pytest tests/test_models.py::test_user_creation -v
```

### Coverage Report

```bash
# Genera report HTML
make test-cov

# Apri report
make coverage
```

### Struttura Test

```
tests/
â”œâ”€â”€ conftest.py              # Fixtures pytest
â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_functions.py
â”‚   â””â”€â”€ test_preprocessing.py
â””â”€â”€ integration/             # Integration tests
    â”œâ”€â”€ test_routes.py
    â””â”€â”€ test_database.py
```

---

## ğŸš¢ Deployment

### Production con Docker

```bash
# Build immagine
docker build -t mec-previsioni:latest .

# Run container
docker run -d \
  -p 5010:5010 \
  -e SECRET_KEY=your-secret-key \
  -e DATABASE_URL=postgresql://... \
  --name mec-previsioni \
  mec-previsioni:latest
```

### Production con Gunicorn

```bash
# Installa dipendenze production
pip install -r requirements.txt

# Configura environment
export SECRET_KEY=your-secret-key
export DATABASE_URL=postgresql://...
export FLASK_ENV=production

# Avvia con gunicorn
gunicorn -w 4 -b 0.0.0.0:5010 "app:create_app(config.ProductionConfig)"
```

### Environment Variables (Production)

```bash
# OBBLIGATORIO
SECRET_KEY=<generate-with-secrets-module>

# Database
DATABASE_URL=postgresql://user:password@host:5432/dbname

# Session
SESSION_COOKIE_SECURE=True

# Logging
LOG_LEVEL=INFO
```

---

## ğŸ” Troubleshooting

### Problema: "SECRET_KEY not set"

**Soluzione:**
```bash
python -c 'import secrets; print(secrets.token_urlsafe(32))'
# Copia output in .env come SECRET_KEY=...
```

### Problema: "ModuleNotFoundError"

**Soluzione:**
```bash
# Verifica virtual environment attivo
which python  # Deve puntare a venv/bin/python

# Reinstalla dipendenze
pip install -r requirements.txt --force-reinstall
```

### Problema: "Database locked" (SQLite)

**Soluzione:**
```bash
# Usa PostgreSQL in production
# Oppure aumenta timeout SQLite in config.py
```

### Problema: File mancanti per modulo Previsioni

**Errore:**
```
FileNotFoundError: File richiesti mancanti per il modulo Previsioni
```

**Soluzione:**
Verificare che esistano:
- `output_rotture_filtrate_completate.xlsx`
- `OUTPUT/output_anagrafica.xlsx`
- `output_modelli.json`
- `output_modelli_per_data.json`

Oppure configurare path custom in `.env`.

### Logs

```bash
# Application logs
tail -f logs/app.log

# Error logs
tail -f logs/errors.log
```

---

## ğŸ“š Documentazione Aggiuntiva

- **[DEVELOPMENT.md](DEVELOPMENT.md)**: Guida sviluppatori completa
- **[DESCRIZIONE_PROGETTO.md](DESCRIZIONE_PROGETTO.md)**: Descrizione tecnica dettagliata
- **[MODELS_STRUCTURE.md](MODELS_STRUCTURE.md)**: Struttura database
- **[MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)**: Guida migrazioni database

---

## ğŸ¤ Contributing

1. Fork del repository
2. Crea feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit delle modifiche (`git commit -m 'feat: Add AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Apri Pull Request

### Commit Message Convention

Usa [Conventional Commits](https://www.conventionalcommits.org/):

- `feat:` Nuova feature
- `fix:` Bug fix
- `docs:` Documentazione
- `style:` Formattazione
- `refactor:` Refactoring
- `test:` Test
- `chore:` Manutenzione

---

## ğŸ“„ Licenza

Proprietario - Tutti i diritti riservati

---

## ğŸ‘¥ Team

Sviluppato da **[Your Team Name]**

---

## ğŸ“ Supporto

Per problemi o domande:
- Apri una issue su GitHub
- Email: support@yourcompany.com
- Documentazione: [Wiki del progetto]

---

**Built with â¤ï¸ using Flask and Python**
